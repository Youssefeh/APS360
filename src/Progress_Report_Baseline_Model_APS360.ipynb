{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/FinalDataset.zip'"
      ],
      "metadata": {
        "id": "k6LH53rcnc6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aPAJmKvbNSS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.cbook import print_cycles\n",
        "import os\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "#Artifical Neural Network Architecture\n",
        "class ANNBaseline(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ANNBaseline, self).__init__()\n",
        "        self.fc1 = nn.Linear(3*224*224,70)\n",
        "        self.fc2 = nn.Linear(70, 30)\n",
        "        self.fc3 = nn.Linear(30, 10)\n",
        "        self.fc4 = nn.Linear(10, 6)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 3*224*224) #flatten feature data\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = (self.fc4(x)).squeeze()\n",
        "        return x\n",
        "        #print(x.shape)\n",
        "        # y = torch.zeros(x.shape[0])\n",
        "        # for i in range(x.shape[0]):\n",
        "        #   y[i] = (x[i].max())\n",
        "        # print(y.shape)\n",
        "        # return y\n",
        "\n",
        "def getLoaders(batch_size = 20):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomRotation([0, 360]),\n",
        "        transforms.GaussianBlur(5),\n",
        "        transforms.RandomHorizontalFlip(p=0.3),\n",
        "        transforms.ToTensor()]\n",
        "    )\n",
        "    absPath = os.path.abspath(\"FinalDataset\")\n",
        "    training_path = absPath + \"/train\"\n",
        "    validation_path = absPath + \"/val\"\n",
        "    testing_path = absPath + \"/test\"\n",
        "    train_set = torchvision.datasets.ImageFolder(root=training_path, transform=transform)\n",
        "    validation_set = torchvision.datasets.ImageFolder(root=validation_path, transform=transform)\n",
        "    testing_set = torchvision.datasets.ImageFolder(root=testing_path, transform=transform)\n",
        "    \n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = torch.utils.data.DataLoader(validation_set, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = torch.utils.data.DataLoader(testing_set, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "def get_accuracy(model, data_loader):\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for imgs, labels in data_loader:\n",
        "    \n",
        "        if torch.cuda.is_available():\n",
        "          imgs = imgs.cuda()\n",
        "          labels = labels.cuda()\n",
        "        \n",
        "        output = model(imgs)\n",
        "        \n",
        "        pred = output.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        total += imgs.shape[0]\n",
        "    return correct / total"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.path import lru_cache\n",
        "def train(model, batch_size=20, num_epochs=1, lr=0.01, momentum=0.9):\n",
        "\n",
        "    train_loader, val_loader, test_loader = getLoaders(batch_size);\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "    train_loss, valid_loss, iters, train_acc, val_acc = [], [], [], [], []\n",
        "\n",
        "\n",
        "    img_to_tensor = transforms.ToTensor()\n",
        "    epochs = []\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        for img, labels in iter(train_loader):\n",
        "\n",
        "          #To Enable GPU Usage\n",
        "          if torch.cuda.is_available():\n",
        "            imgs = imgs.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "          out = model((img))\n",
        "\n",
        "          loss = criterion(out, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "        train_loss.append(float(loss))\n",
        "\n",
        "        for img, labels in iter(val_loader):\n",
        "            out = model(img)\n",
        "            loss = criterion(out, labels)\n",
        "        valid_loss.append(float(loss))\n",
        "\n",
        "        epochs.append(epoch)\n",
        "        train_acc.append(get_accuracy(model, train_loader))\n",
        "        val_acc.append(get_accuracy(model, val_loader))\n",
        "        print(\"Epoch %d; Loss %f; Train Acc %f; Val Acc %f\" % (\n",
        "              epoch+1, loss, train_acc[-1], val_acc[-1]))\n",
        "        \n",
        "    # plotting\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(train_loss, label=\"Train\")\n",
        "    plt.plot(valid_loss, label=\"Valid\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(epochs, train_acc, label=\"Train\")\n",
        "    plt.plot(epochs, val_acc, label=\"Validation\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "NHYyW-vYnhOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ANNBaseline()\n",
        "train(model, batch_size=57, num_epochs=20, lr=0.04)"
      ],
      "metadata": {
        "id": "wDw7IPFPxYO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get testing accuracy\n",
        "train_loader, val_loader, test_loader = getLoaders(40);\n",
        "print(\"Accuracy:\",get_accuracy(model, test_loader))\n",
        "\n"
      ],
      "metadata": {
        "id": "_l66kGOY8QBZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}